# Spark â€” Project Vision

**Domain:** [sparkagent.dev](https://sparkagent.dev)
**Repo:** github.com/jcottam/retain (rename pending)

---

## What Is This?

Spark is a minimal AI agent framework built from scratch to understand â€” brick by brick â€” how agentic systems work. It's a learning lab, not a product competitor.

The goal: deeply understand the architecture behind tools like OpenClaw, LangChain, and similar agent frameworks by building one from zero.

## Why Open Source?

- **Learning in public** â€” forces cleaner code, better docs, sharper thinking
- **Portfolio piece** â€” proof that a Director of Engineering can still build, not just manage
- **Content companion** â€” blog posts on [noteworthy.solutions](https://noteworthy.solutions) will walk through the decisions and patterns discovered here
- **Community** â€” others learning the same patterns can follow along, contribute, or fork

## Core Pillars

1. **Memory** â€” what to remember, how to recall, when to forget
2. **Context Assembly** â€” building the right prompt from scattered sources
3. **Tool Use** â€” how agents safely interact with the real world
4. **Session Continuity** â€” making a stateless model feel stateful
5. **Provider Abstraction** â€” same agent logic, any model underneath (Anthropic, OpenAI, Ollama, etc.)
6. **Skills & MCP** â€” pluggable capabilities via Model Context Protocol servers

## Architecture Direction

```
spark/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/           # Shared: db, memory, sessions, context, tools
â”‚   â”œâ”€â”€ providers/      # Model adapters (Anthropic, OpenAI, Ollama)
â”‚   â”œâ”€â”€ cli/            # Ink TUI (primary interface)
â”‚   â”œâ”€â”€ server/         # Hono API backend
â”‚   â””â”€â”€ web/            # Dashboard frontend
```

### Key Decisions

- **Runtime:** Bun
- **Storage:** SQLite (local-first, via bun:sqlite)
- **Semantic Search:** Upstash Vector (optional)
- **CLI UI:** React + Ink
- **API:** Hono (runs natively on Bun)
- **Frontend:** TBD (lightweight â€” possibly HTMX or minimal React)

### Interfaces (in order of priority)

1. **CLI** â€” `spark chat`, `spark search`, `spark serve`
2. **Web Dashboard** â€” search memories, review sessions, manage cron/tools/config
3. **Web Chat** â€” full chat via SSE streaming through the Hono API
4. **Chrome Extension** â€” context-aware AI anywhere in the browser (highlight â†’ remember, right-click â†’ ask)

### Hosting Model

- Local-first for CLI
- Self-hosted API for web + extension (single VPS, SQLite, Cloudflare Tunnel)
- No multi-tenant complexity unless/until needed

## Philosophy

- **Keep it minimal.** Add features to learn patterns, not to ship a product.
- **Document the journey.** The real output is understanding, not code.
- **Experiment freely.** Try different memory strategies, context windows, provider quirks.
- **Ship ugly.** Polish comes after comprehension.

## Current State (as of February 2026)

- âœ… CLI chat with persistent memory (SQLite + JSONL)
- âœ… Session resume and search (FTS5)
- âœ… Memory extraction via `[MEMORY]` tags
- âœ… Optional semantic recall (Upstash Vector)
- âœ… Tool use (read_file, write_file, run_command)
- âœ… Test suite (db, memory, session, tools, context)
- ðŸ”² Model-agnostic provider layer
- ðŸ”² MCP server integration
- ðŸ”² Skills/plugin system
- ðŸ”² Hono API backend
- ðŸ”² Web dashboard
- ðŸ”² Web chat
- ðŸ”² Chrome extension
- ðŸ”² Rename from MiniChat â†’ Spark

## Author

**John Ryan Cottam** â€” Director of Engineering, fullstack developer since 2000, building the future one brick at a time.

- [noteworthy.solutions](https://noteworthy.solutions)
- [github.com/jcottam](https://github.com/jcottam)
